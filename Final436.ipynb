{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snhuq/msci436.project/blob/main/Final436.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Yp2TnJ-eqO"
      },
      "outputs": [],
      "source": [
        "# Install the Kaggle API client\n",
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Upload your kaggle.json file\n",
        "files.upload()\n",
        "\n",
        "# Create the .kaggle directory and move the kaggle.json file there\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d alshival/nhtsa-complaints\n",
        "\n",
        "# Unzip the downloaded dataset\n",
        "!unzip -o nhtsa-complaints.zip\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets from the downloaded files\n",
        "car_models = pd.read_csv('car_models.csv')\n",
        "complaints = pd.read_csv('complaints.csv')\n",
        "investigations = pd.read_csv('investigations.csv')\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "recalls = pd.read_csv('recalls.csv')\n",
        "\n",
        "# Checking first few rows of each dataset to make sure they are loaded correctly\n",
        "  print(\"Car Models Data\")\n",
        "  print(car_models.head())\n",
        "\n",
        "  print(\"\\nComplaints Data\")\n",
        "  print(complaints.head())\n",
        "\n",
        "  print(\"\\nInvestigations Data\")\n",
        "  print(investigations.head())\n",
        "\n",
        "  print(\"\\nRatings Data\")\n",
        "  print(ratings.head())\n",
        "\n",
        "  print(\"\\nRecalls Data\")\n",
        "  print(recalls.head())\n",
        "\n",
        "# Inspect columns of each dataframe\n",
        "  print(\"Car Models Columns:\", car_models.columns)\n",
        "  print(\"Complaints Columns:\", complaints.columns)\n",
        "  print(\"Investigations Columns:\", investigations.columns)\n",
        "  print(\"Ratings Columns:\", ratings.columns)\n",
        "  print(\"Recalls Columns:\", recalls.columns)\n",
        "\n",
        "# Rename columns to make it consistent\n",
        "    complaints.rename(columns={'make': 'Make', 'model': 'Model', 'modelYear': 'ModelYear'}, inplace=True)\n",
        "    recalls.rename(columns={'Make': 'Make', 'Model': 'Model', 'ModelYear': 'ModelYear'}, inplace=True)\n",
        "    ratings.rename(columns={'Make': 'Make', 'Model': 'Model', 'ModelYear': 'ModelYear'}, inplace=True)\n",
        "    investigations.rename(columns={'MAKE': 'Make', 'MODEL': 'Model', 'YEAR': 'ModelYear'}, inplace=True)\n",
        "\n",
        "# Drop rows with missing values to maintain data quality\n",
        "    car_models.dropna(inplace=True)\n",
        "    complaints.dropna(inplace=True)\n",
        "    investigations.dropna(inplace=True)\n",
        "    ratings.dropna(inplace=True)\n",
        "    recalls.dropna(inplace=True)\n",
        "\n",
        "# Clean Investigations Data\n",
        "# Replace '.' with NaN and then convert YEAR as integer\n",
        "    investigations.replace('.', pd.NA, inplace=True)\n",
        "    investigations['ModelYear'] = pd.to_numeric(investigations['ModelYear'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Fill or drop missing values based on context\n",
        "  investigations.fillna({\n",
        "    'CAMPNO': 'Unknown',\n",
        "    'SUBJECT': 'Unknown',\n",
        "    'SUMMARY': 'No summary available',\n",
        "    'MFR_NAME': 'Unknown Manufacturer'\n",
        "}, inplace=True)\n",
        "\n",
        "# Verify that all columns have consistent data types\n",
        "  print(\"\\nInvestigations Data Types after Cleaning:\")\n",
        "  print(investigations.dtypes)\n",
        "\n",
        "# Perform the merge operation using the common columns\n",
        "  try:\n",
        "      merged_data = pd.merge(complaints, recalls, on=['Make', 'Model', 'ModelYear'])\n",
        "      merged_data = pd.merge(merged_data, ratings, on=['Make', 'Model', 'ModelYear'])\n",
        "      merged_data = pd.merge(merged_data, investigations, on=['Make', 'Model', 'ModelYear'])\n",
        "    print(\"\\nMerged Data\")\n",
        "    print(merged_data.head())\n",
        "  except KeyError as e:\n",
        "    print(f\"KeyError: {e}\")\n",
        "    print(\"Please verify the common column name and ensure it exists in all dataframes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the duplicate entries\n",
        "  merged_data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle missing values by filling with appropriate values or drop\n",
        "  merged_data.fillna({\n",
        "    'numberOfInjuries': 0,\n",
        "    'numberOfDeaths': 0,\n",
        "    'crash': False,\n",
        "    'fire': False,\n",
        "    'OverallRating': merged_data['OverallRating'].mode()[0] if 'OverallRating' in merged_data else 5,\n",
        "    'SideCrashDriversideRating': merged_data['SideCrashDriversideRating'].mode()[0] if 'SideCrashDriversideRating' in merged_data else 'Not Rated'\n",
        "}, inplace=True)\n",
        "\n",
        "# Display the first few rows of the merged data after handling missing values\n",
        "  print(\"\\nMerged Data after Handling Missing Values\")\n",
        "  print(merged_data.head())\n",
        "\n",
        "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "    from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "  import joblib\n",
        "  import numpy as np\n",
        "\n",
        "# Feature Engineering: Create additional features\n",
        "    merged_data['incident_year'] = pd.to_datetime(merged_data['dateOfIncident']).dt.year\n",
        "    merged_data['vehicle_age'] = merged_data['incident_year'] - merged_data['ModelYear']\n",
        "\n",
        "# Select relevant features for the model\n",
        "  features = merged_data[['Make', 'Model', 'ModelYear', 'numberOfInjuries', 'numberOfDeaths',\n",
        "                        'crash', 'fire', 'OverallRating', 'SideCrashDriversideRating',\n",
        "                        'vehicle_age']]\n",
        "\n",
        "# One-Hot Encode categorical features\n",
        "    categorical_features = ['Make', 'Model', 'OverallRating', 'SideCrashDriversideRating']\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')  # Avoiding dummy variable trap\n",
        "    encoded_categorical = encoder.fit_transform(features[categorical_features])\n",
        "    encoded_categorical_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_features))\n",
        "\n",
        "# Normalize numerical features\n",
        "    numerical_features = ['ModelYear', 'numberOfInjuries', 'numberOfDeaths', 'vehicle_age']\n",
        "    scaler = StandardScaler()\n",
        "    scaled_numerical = scaler.fit_transform(features[numerical_features])\n",
        "    scaled_numerical_df = pd.DataFrame(scaled_numerical, columns=numerical_features)\n",
        "\n",
        "# Combine the encoded categorical and scaled numerical features\n",
        "  final_features = pd.concat([encoded_categorical_df, scaled_numerical_df], axis=1)\n",
        "\n",
        "# Display the first few rows of the final features to ensure everything is correct\n",
        "  print(\"\\nFinal Features for Modeling\")\n",
        "  print(final_features.head())\n",
        "\n",
        "# Assuming 'Recall' is the target variable in the merged_data\n",
        "# Adjust the name of the target variable if necessary\n",
        "\n",
        "# For demonstration, I'll create a dummy target variable\n",
        "    merged_data['Recall'] = np.random.choice([0, 1], size=merged_data.shape[0])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "    X = final_features\n",
        "    y = merged_data['Recall']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Balancing dataset using SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "  param_grid = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "  grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='f1')\n",
        "  grid_search.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Best model from grid search\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "# Cross-validation score\n",
        "    cv_scores = cross_val_score(best_model, X_train_balanced, y_train_balanced, cv=5, scoring='f1')\n",
        "  print(f\"Cross-Validation F1 Score: {np.mean(cv_scores):.2f}\")\n",
        "\n",
        "# Train the best model\n",
        "    best_model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions on the test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  print(\"\\nAccuracy Score:\")\n",
        "  print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Model Performance Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "  print(f\"Precision: {precision:.2f}\")\n",
        "  print(f\"Recall: {recall:.2f}\")\n",
        "  print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Revised Cost Savings Estimation\n",
        "# Assumptions:\n",
        "# - Cost of a recall: $11000 per vehicle (Hyundai EV)\n",
        "# - Cost of not recalling a faulty vehicle (e.g., lawsuits, fines): $3600000\n",
        "# - Percentage of true positives that lead to actual recalls: 80%\n",
        "\n",
        "    cost_of_recall = 11000\n",
        "    cost_of_no_action = 3600000\n",
        "    true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "# Calculate savings only when recalls prevent lawsuits\n",
        "  prevented_lawsuits = true_positives * cost_of_no_action * 0.8\n",
        "  cost_of_recalls = true_positives * cost_of_recall\n",
        "  cost_savings = prevented_lawsuits - cost_of_recalls\n",
        "  print(f\"Estimated Cost Savings: ${cost_savings:,.2f}\")\n",
        "\n",
        "# Time Efficiency remains the same\n",
        "# Potential Safety Issues Identified remains the same\n",
        "# Improvement in Customer Satisfaction remains the same\n",
        "\n",
        "# Time Efficiency\n",
        "# Assumptions:\n",
        "# - Manual process cost: $520 per vehicle repair (average car repair cost)\n",
        "# - Automated system cost: $470000 for the first year and $70000 per year after\n",
        "# - Total predictions per month: 1000\n",
        "\n",
        "    manual_process_cost_per_vehicle = 520\n",
        "    automated_system_first_year_cost = 470000\n",
        "    automated_system_annual_cost = 70000\n",
        "    total_predictions_per_month = 1000\n",
        "\n",
        "# Calculate the total cost for one year of manual vs automated\n",
        "    manual_total_cost_first_year = total_predictions_per_month * 12 * manual_process_cost_per_vehicle\n",
        "    automated_total_cost_first_year = automated_system_first_year_cost + automated_system_annual_cost\n",
        "\n",
        "# Calculate cost savings after the first year\n",
        "    manual_total_cost_second_year = total_predictions_per_month * 12 * manual_process_cost_per_vehicle\n",
        "    automated_total_cost_second_year = automated_system_annual_cost\n",
        "\n",
        "    first_year_savings = manual_total_cost_first_year - automated_total_cost_first_year\n",
        "    second_year_savings = manual_total_cost_second_year - automated_total_cost_second_year\n",
        "\n",
        "  print(f\"First Year Cost Savings: ${first_year_savings:,.2f}\")\n",
        "  print(f\"Second Year Cost Savings: ${second_year_savings:,.2f}\")\n",
        "\n",
        "# Potential Safety Issues Identified\n",
        "    potential_safety_issues = np.sum(y_pred == 1)\n",
        "  print(f\"Potential Safety Issues Identified: {potential_safety_issues}\")\n",
        "\n",
        "# Improvement in Customer Satisfaction\n",
        "# Assumptions:\n",
        "# - Improvement in customer satisfaction per proactive recall: 5%\n",
        "# - Number of proactive recalls per month: equal to the number of true positives\n",
        "\n",
        "    improvement_per_recall = 0.05\n",
        "    customer_satisfaction_improvement = true_positives * improvement_per_recall\n",
        "  print(f\"Estimated Improvement in Customer Satisfaction: {customer_satisfaction_improvement * 100:.2f}%\")\n",
        "\n",
        "# Save the best model and transformers for future use\n",
        "  joblib.dump(best_model, 'recall_prediction_model_best.joblib')\n",
        "  joblib.dump(encoder, 'encoder_best.joblib')\n",
        "  joblib.dump(scaler, 'scaler_best.joblib')\n",
        "\n",
        "  print(\"Best model, encoder, and scaler have been saved for future use.\")\n",
        "\n",
        "# Export Data for Power BI\n",
        "# Model performance metrics\n",
        "  model_performance = pd.DataFrame({\n",
        "      'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "      'Score': [accuracy, precision, recall, f1]\n",
        "  })\n",
        "\n",
        "  # Cost analysis data\n",
        "  cost_analysis = pd.DataFrame({\n",
        "      'Year': ['First Year', 'Second Year'],\n",
        "      'Manual Cost': [manual_total_cost_first_year, manual_total_cost_second_year],\n",
        "      'Automated Cost': [automated_total_cost_first_year, automated_total_cost_second_year],\n",
        "      'Cost Savings': [first_year_savings, second_year_savings]\n",
        "  })\n",
        "\n",
        "# Prediction metrics\n",
        "  true_positives = np.sum((y_test == 1) & (y_pred == 1))\n",
        "  false_positives = np.sum((y_test == 0) & (y_pred == 1))\n",
        "  true_negatives = np.sum((y_test == 0) & (y_pred == 0))\n",
        "  false_negatives = np.sum((y_test == 1) & (y_pred == 0))\n",
        "\n",
        "  predictions = pd.DataFrame({\n",
        "      'Metric': ['True Positives', 'False Positives', 'True Negatives', 'False Negatives'],\n",
        "      'Count': [true_positives, false_positives, true_negatives, false_negatives]\n",
        "  })\n",
        "\n",
        "# Export Investigations Data for Power BI\n",
        "    investigations.to_csv('investigations_cleaned.csv', index=False)\n",
        "\n",
        "# Save dataframes to CSV\n",
        "    model_performance.to_csv('model_performance.csv', index=False)\n",
        "    cost_analysis.to_csv('cost_analysis.csv', index=False)\n",
        "    predictions.to_csv('predictions.csv', index=False)\n",
        "\n",
        "# Download the CSV files to your local machine\n",
        "  from google.colab import files\n",
        "    files.download('model_performance.csv')\n",
        "    files.download('cost_analysis.csv')\n",
        "    files.download('predictions.csv')\n",
        "    files.download('investigations_cleaned.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "41Ywn57P_K0X",
        "outputId": "19b4ee1e-db8f-46ce-9dfa-e630234e7a6e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merged Data after Handling Missing Values\n",
            "   odiNumber           manufacturer  crash   fire  numberOfInjuries  \\\n",
            "0   11555100  Hyundai Motor America  False  False                 0   \n",
            "1   11555100  Hyundai Motor America  False  False                 0   \n",
            "2   11555100  Hyundai Motor America  False  False                 0   \n",
            "3   11555100  Hyundai Motor America  False  False                 0   \n",
            "4   11571460  Hyundai Motor America  False  False                 0   \n",
            "\n",
            "   numberOfDeaths dateOfIncident dateComplaintFiled          vin  \\\n",
            "0               0     11/13/2023         11/14/2023  KM8KRDDF4RU   \n",
            "1               0     11/13/2023         11/14/2023  KM8KRDDF4RU   \n",
            "2               0     11/13/2023         11/14/2023  KM8KRDDF4RU   \n",
            "3               0     11/13/2023         11/14/2023  KM8KRDDF4RU   \n",
            "4               0     02/12/2024         02/12/2024  KM8KRDDF7RU   \n",
            "\n",
            "                                          components  ... VehicleId  \\\n",
            "0                                  ELECTRICAL SYSTEM  ...     19546   \n",
            "1                                  ELECTRICAL SYSTEM  ...     19546   \n",
            "2                                  ELECTRICAL SYSTEM  ...     19547   \n",
            "3                                  ELECTRICAL SYSTEM  ...     19547   \n",
            "4  ELECTRICAL SYSTEM,VEHICLE SPEED CONTROL,FUEL/P...  ...     19546   \n",
            "\n",
            "                  rating_updated_on NHTSA ACTION NUMBER  \\\n",
            "0  2024-07-09 10:10:10.173163+00:00             PE23011   \n",
            "1  2024-07-09 10:10:10.173163+00:00             PE23011   \n",
            "2  2024-07-05 09:08:42.598049+00:00             PE23011   \n",
            "3  2024-07-05 09:08:42.598049+00:00             PE23011   \n",
            "4  2024-07-09 10:10:10.173163+00:00             PE23011   \n",
            "\n",
            "                                            COMPNAME               MFR_NAME  \\\n",
            "0              ELECTRICAL SYSTEM:12V/24V/48V BATTERY  Hyundai Motor America   \n",
            "1  ELECTRICAL SYSTEM:PROPULSION SYSTEM:DC/DC CONV...  Hyundai Motor America   \n",
            "2              ELECTRICAL SYSTEM:12V/24V/48V BATTERY  Hyundai Motor America   \n",
            "3  ELECTRICAL SYSTEM:PROPULSION SYSTEM:DC/DC CONV...  Hyundai Motor America   \n",
            "4              ELECTRICAL SYSTEM:12V/24V/48V BATTERY  Hyundai Motor America   \n",
            "\n",
            "        ODATE       CDATE  CAMPNO                SUBJECT  \\\n",
            "0  20230608.0  20240417.0  24V204  Loss of Motive Power    \n",
            "1  20230608.0  20240417.0  24V204  Loss of Motive Power    \n",
            "2  20230608.0  20240417.0  24V204  Loss of Motive Power    \n",
            "3  20230608.0  20240417.0  24V204  Loss of Motive Power    \n",
            "4  20230608.0  20240417.0  24V204  Loss of Motive Power    \n",
            "\n",
            "                                             SUMMARY  \n",
            "0  On June 8, 2023, the Office of Defect Investig...  \n",
            "1  On June 8, 2023, the Office of Defect Investig...  \n",
            "2  On June 8, 2023, the Office of Defect Investig...  \n",
            "3  On June 8, 2023, the Office of Defect Investig...  \n",
            "4  On June 8, 2023, the Office of Defect Investig...  \n",
            "\n",
            "[5 rows x 56 columns]\n",
            "\n",
            "Final Features for Modeling\n",
            "   ModelYear  numberOfInjuries  numberOfDeaths  vehicle_age\n",
            "0        0.0               0.0             0.0    -2.236068\n",
            "1        0.0               0.0             0.0    -2.236068\n",
            "2        0.0               0.0             0.0    -2.236068\n",
            "3        0.0               0.0             0.0    -2.236068\n",
            "4        0.0               0.0             0.0     0.447214\n",
            "Cross-Validation F1 Score: 0.34\n",
            "Confusion Matrix:\n",
            "[[1 1]\n",
            " [0 3]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.88      0.75      0.76         5\n",
            "weighted avg       0.85      0.80      0.78         5\n",
            "\n",
            "\n",
            "Accuracy Score:\n",
            "0.8\n",
            "Accuracy: 0.80\n",
            "Precision: 0.75\n",
            "Recall: 1.00\n",
            "F1 Score: 0.86\n",
            "Estimated Cost Savings: $8,607,000.00\n",
            "First Year Cost Savings: $5,700,000.00\n",
            "Second Year Cost Savings: $6,170,000.00\n",
            "Potential Safety Issues Identified: 4\n",
            "Estimated Improvement in Customer Satisfaction: 15.00%\n",
            "Best model, encoder, and scaler have been saved for future use.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4ca95622-e4bc-405c-8110-af60b2e8090a\", \"model_performance.csv\", 80)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f8e17649-a0f0-4dad-848f-64a4a0fd0daf\", \"cost_analysis.csv\", 113)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cdbce815-f23a-4c05-8cf6-9259edf9ea61\", \"predictions.csv\", 83)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f3045b49-6284-49a6-9ba0-4367e07abddb\", \"investigations_cleaned.csv\", 106084876)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}